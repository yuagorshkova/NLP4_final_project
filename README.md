О файлах в репозитории:

- `dev_aspects_spans_predicted.txt`, `pred_categories.txt` -- файлы для Evaluation с предсказаниями для задач выделения спанов аспектов и анализа сентимента отзыва по категориям.
- `Aspect_extraction.ipynb` -- тетрадка с кодом реализации решения задачи выделения спанов.
- `CategorySentiment.ipynb` -- тетрадка с кодом реализации решения задачи определения тональности по категориям.
- `CategorySentiment_inference.ipynb` - тетрадка для предсказания категорий с чекпоинта на новых данных. Ее нужно скачать и заупстить у себя в колабе, внутри есть подробная инструкция.


## Aspect Extraction

Для выделения аспектов мы разметили тексты в BIO-формате (для учета контекста) и на размеченных данных обучили CRF с параметрами из семинарской тетрадки, несмотря на то, что распределение классов получилось неравномерным, 

| Tag        | Number |
|------------|--------|
| B-Food     | 1877   |
| B-Service  | 1246   |
| I-Food     | 959    |
| B-Whole    | 795    |
| B-Interior | 686    |
| I-Service  | 283    |
| I-Interior | 189    |
| I-Whole    | 187    |
| B-Price    | 134    |
| I-Price    | 30     |

качество разметки значительно превысило бэйзлайн

| Metrics                 | Baseline | CRF |
|-----------------------------|--------------|---------|
| Full match precision        |     0.48     |   0.95  |
| Full match recall           |     0.71     |   0.94  |
| Partial match ratio in pred |     0.61     |   0.96  |
| Full category accuracy      |     0.46     |   0.94  |
| Partial category accuracy   |     0.60     |   0.96  |


## Category Sentiment Analysis

Задача решалась как мультитаск-мультиклассова классификация; один таск соответствовал определению сентимента одной категории, классов было 5: absence, negative, neutral, positive, both. На каждом шаге обучения считалась кросс-энтропия для всех задач, затем оптимизировалась сумма всех пяти лоссов. Таким образом, во время обучения модель должны была принимать во внимание возможные тональности остальных категорий (например, если по каждой категории в отдельности человек выразил позитивную оценку, то лейбл Whole тоже должен быть позитивный). В качестве энкодера были взяты веса предобученоного sberbank-ai/ruBert-base (эмбеддинги не дообучались, чтобы уменьшить вес shareable чекпоинта; локально есть чекпоинт, где берт дообучался -- он более стабильный и дает лучшее качество). К cls токену последовательности применялся один fully-connected слой для классификации.

Качество:
| Category   | Acc    |
|------------|--------|
| Food       | 0.704  |
| Service    | 0.662  |
| Food       | 0.511  |
| Whole      | 0.718  |
| Interior   | 0.637  |
| Overall    | 0.646  |

Модель, где дообучался берт, показывала accuracy 0.727
